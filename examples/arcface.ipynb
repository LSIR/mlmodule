{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Similarity Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import `mozuma` modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "from mozuma.torch.options import TorchRunnerOptions\n",
    "from mozuma.torch.runners import TorchInferenceRunner\n",
    "from mozuma.callbacks.memory import (\n",
    "    CollectBoundingBoxesInMemory,\n",
    "    CollectFeaturesInMemory,\n",
    ")\n",
    "from mozuma.torch.datasets import (\n",
    "    LocalBinaryFilesDataset,\n",
    "    ImageDataset,\n",
    "    ImageBoundingBoxDataset,\n",
    ")\n",
    "from mozuma.helpers.files import list_files_in_dir\n",
    "\n",
    "from mozuma.models.mtcnn.pretrained import torch_mtcnn\n",
    "from mozuma.models.arcface.pretrained import torch_arcface_insightface\n",
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from facenet_pytorch.models.utils.detect_face import crop_resize\n",
    "from PIL import Image\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set(style=\"white\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "base_path = \"../../tests/fixtures/berset\"\n",
    "file_names = list_files_in_dir(base_path, allowed_extensions=(\"jpg\",))\n",
    "# Load image dataset\n",
    "berset_dataset = ImageDataset(LocalBinaryFilesDataset(file_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run face detection with `torch_mtcnn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_device = torch.device(\"cpu\")\n",
    "face_detector = torch_mtcnn(device=torch_device)\n",
    "\n",
    "# Callbacks\n",
    "bb = CollectBoundingBoxesInMemory()\n",
    "\n",
    "# Runner\n",
    "runner = TorchInferenceRunner(\n",
    "    model=face_detector,\n",
    "    dataset=berset_dataset,\n",
    "    callbacks=[bb],\n",
    "    options=TorchRunnerOptions(\n",
    "        data_loader_options={\"batch_size\": 1}, device=torch_device, tqdm_enabled=True\n",
    "    ),\n",
    ")\n",
    "runner.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract face features with `TorchArcFaceModule`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arcface = torch_arcface_insightface(device=torch_device)\n",
    "\n",
    "# Dataset\n",
    "dataset = ImageBoundingBoxDataset(\n",
    "    image_dataset=ImageDataset(LocalBinaryFilesDataset(bb.indices)),\n",
    "    bounding_boxes=bb.bounding_boxes,\n",
    ")\n",
    "\n",
    "# Callbacks\n",
    "ff = CollectFeaturesInMemory()\n",
    "\n",
    "# Runner\n",
    "runner = TorchInferenceRunner(\n",
    "    model=arcface,\n",
    "    dataset=dataset,\n",
    "    callbacks=[ff],\n",
    "    options=TorchRunnerOptions(\n",
    "        data_loader_options={\"batch_size\": 3}, device=torch_device, tqdm_enabled=True\n",
    "    ),\n",
    ")\n",
    "runner.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the cropped faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "def image_grid(array, ncols=10):\n",
    "    index, height, width, channels = array.shape\n",
    "    nrows = index // ncols\n",
    "    img_grid = (\n",
    "        array.reshape(nrows, ncols, height, width, channels)\n",
    "        .swapaxes(1, 2)\n",
    "        .reshape(height * nrows, width * ncols, channels)\n",
    "    )\n",
    "\n",
    "    return img_grid\n",
    "\n",
    "\n",
    "img_arr = []\n",
    "for k, file_name in enumerate(bb.indices):\n",
    "    img = Image.open(file_name).convert(\"RGB\")\n",
    "    bboxes = bb.bounding_boxes[k]\n",
    "    for box in bboxes.bounding_boxes:\n",
    "        cropped_face = np.asarray(crop_resize(img, box, image_size=112))\n",
    "        img_arr.append(cropped_face)\n",
    "\n",
    "result = image_grid(np.array(img_arr), ncols=len(img_arr))\n",
    "fig = plt.figure(figsize=(20.0, 20.0))\n",
    "plt.imshow(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute face similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "sim_mat = ff.features @ ff.features.T\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "ax = sns.heatmap(sim_mat, cmap=\"PuRd\", annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this heatmap, we can see that the cosine similarities between the three faces of Alain Berset is quite high (from 0.7 to 0.74) while they are very low between all other faces."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "355aa20d4ad8dc39dec281b3934cd3d34f60aab58844993f6361175a2b6f9a83"
  },
  "jupytext": {
   "formats": "ipynb,md",
   "main_language": "python"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit (conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
