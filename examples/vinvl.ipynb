{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object Detection with VinVL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import `mozuma` modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mozuma.torch.options import TorchRunnerOptions\n",
    "from mozuma.torch.runners import TorchInferenceRunner\n",
    "from mozuma.callbacks.memory import (\n",
    "    CollectBoundingBoxesInMemory,\n",
    ")\n",
    "from mozuma.helpers.files import list_files_in_dir\n",
    "from mozuma.torch.datasets import LocalBinaryFilesDataset, ImageDataset\n",
    "from mozuma.models.vinvl.pretrained import torch_vinvl_detector\n",
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = os.path.join(\"../../tests\", \"fixtures\", \"objects\")\n",
    "file_names = list_files_in_dir(base_path, allowed_extensions=(\"jpg\",))[:50]\n",
    "dataset = ImageDataset(LocalBinaryFilesDataset(file_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run object detection with `torch_vinvl_detector`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load VinVL model (it might take a few minutes.)\n",
    "torch_device = torch.device(\"cuda\")\n",
    "vinvl = torch_vinvl_detector(device=torch_device, score_threshold=0.5)\n",
    "\n",
    "bb = CollectBoundingBoxesInMemory()\n",
    "\n",
    "# Runner\n",
    "runner = TorchInferenceRunner(\n",
    "    model=vinvl,\n",
    "    dataset=dataset,\n",
    "    callbacks=[bb],\n",
    "    options=TorchRunnerOptions(\n",
    "        device=torch_device, data_loader_options={\"batch_size\": 10}, tqdm_enabled=True\n",
    "    ),\n",
    ")\n",
    "runner.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualise the detected objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First get labels and attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, img_path in enumerate(bb.indices):\n",
    "    print(f\"Object detected for {img_path}\")\n",
    "    img = Image.open(img_path).convert(\"RGB\")\n",
    "    plt.figure()\n",
    "    plt.imshow(img)\n",
    "    bboxes = bb.bounding_boxes[i].bounding_boxes\n",
    "    scores = bb.bounding_boxes[i].scores\n",
    "    for k, bbox in enumerate(bboxes):\n",
    "        bbox0, bbox1, bbox2, bbox3 = bbox\n",
    "        plt.gca().add_patch(\n",
    "            Rectangle(\n",
    "                (bbox0, bbox1),\n",
    "                bbox2 - bbox0,\n",
    "                bbox3 - bbox1,\n",
    "                fill=False,\n",
    "                edgecolor=\"red\",\n",
    "                linewidth=2,\n",
    "                alpha=0.5,\n",
    "            )\n",
    "        )\n",
    "        plt.text(bbox0, bbox1, f\"{scores[k]*100:.1f}%\", color=\"blue\", fontsize=12)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1a9eeca477439d6a2922d69b8d743e1024f2fe4120e7a870f9cdb2970f0e81af"
  },
  "jupytext": {
   "formats": "ipynb,md",
   "main_language": "python"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit (conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
