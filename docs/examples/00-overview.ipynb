{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d7b1dfa",
   "metadata": {},
   "source": [
    "# MoZuMa overview\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44ecbe0",
   "metadata": {},
   "source": [
    "# Downloading images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6471ee1b",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "import requests\n",
    "\n",
    "IMAGE_URLS = [\n",
    "    \"https://images.pexels.com/photos/13021281/pexels-photo-13021281.jpeg?cs=srgb&dl=pexels-moaz-tobok-13021281.jpg&fm=jpg&w=1280&h=1920\",\n",
    "    \"https://images.pexels.com/photos/13168607/pexels-photo-13168607.jpeg?cs=srgb&dl=pexels-valeria-boltneva-13168607.jpg&fm=jpg&w=1280&h=1919\",\n",
    "    \"https://images.pexels.com/photos/4327709/pexels-photo-4327709.jpeg?cs=srgb&dl=pexels-jess-loiterton-4327709.jpg&fm=jpg&w=1280&h=1707\",\n",
    "    \"https://images.pexels.com/photos/4327792/pexels-photo-4327792.jpeg?cs=srgb&dl=pexels-jess-loiterton-4327792.jpg&fm=jpg&w=1280&h=1600\",\n",
    "    \"https://images.pexels.com/photos/3773651/pexels-photo-3773651.jpeg?cs=srgb&dl=pexels-arnie-watkins-3773651.jpg&fm=jpg&w=1280&h=1600\",\n",
    "    \"https://images.pexels.com/photos/2962392/pexels-photo-2962392.jpeg?cs=srgb&dl=pexels-symeon-ekizoglou-2962392.jpg&fm=jpg&w=1280&h=1852\",\n",
    "    \"https://images.pexels.com/photos/2407089/pexels-photo-2407089.jpeg?cs=srgb&dl=pexels-flynn-grey-2407089.jpg&fm=jpg&w=1280&h=853\",\n",
    "    # Kayak sea cave\n",
    "    \"https://images.pexels.com/photos/2847862/pexels-photo-2847862.jpeg?cs=srgb&dl=pexels-ngoc-vuong-2847862.jpg&fm=jpg&w=1280&h=850\",\n",
    "    # Kayak sea\n",
    "    \"https://images.pexels.com/photos/1430672/pexels-photo-1430672.jpeg?cs=srgb&dl=pexels-asad-photo-maldives-1430672.jpg&fm=jpg&w=1280&h=863\",\n",
    "    # Kayak mountain\n",
    "    \"https://images.pexels.com/photos/1497582/pexels-photo-1497582.jpeg?cs=srgb&dl=pexels-spencer-gurley-films-1497582.jpg&fm=jpg&w=1280&h=854\",\n",
    "    \"https://images.pexels.com/photos/13759/pexels-photo-13759.jpeg?cs=srgb&dl=pexels-jamie-hutt-13759.jpg&fm=jpg&w=1280&h=960\",\n",
    "    \"https://images.pexels.com/photos/1252396/pexels-photo-1252396.jpeg?cs=srgb&dl=pexels-headshatter-1252396.jpg&fm=jpg&w=1280&h=1920\",\n",
    "    # Kayak helmet\n",
    "    \"https://images.pexels.com/photos/2283103/pexels-photo-2283103.jpeg?cs=srgb&dl=pexels-brett-sayles-2283103.jpg&fm=jpg&w=1280&h=852\",\n",
    "    # Moto\n",
    "    \"https://images.pexels.com/photos/39693/motorcycle-racer-racing-race-speed-39693.jpeg?cs=srgb&dl=pexels-pixabay-39693.jpg&fm=jpg&w=1280&h=850\",\n",
    "    # Dog\n",
    "    \"https://images.pexels.com/photos/58997/pexels-photo-58997.jpeg?cs=srgb&dl=pexels-muhannad-alatawi-58997.jpg&fm=jpg&w=1280&h=853\",\n",
    "    \"https://images.pexels.com/photos/1254140/pexels-photo-1254140.jpeg?cs=srgb&dl=pexels-johann-1254140.jpg&fm=jpg&w=1280&h=853\",\n",
    "    \"https://images.pexels.com/photos/551628/pexels-photo-551628.jpeg?cs=srgb&dl=pexels-kat-smith-551628.jpg&fm=jpg&w=1280&h=854\",\n",
    "    # Sea cave\n",
    "    \"https://images.pexels.com/photos/163872/italy-cala-gonone-air-sky-163872.jpeg?cs=srgb&dl=pexels-pixabay-163872.jpg&fm=jpg&w=1280&h=960\",\n",
    "]\n",
    "\n",
    "KAYAK_IMAGE = \"https://images.pexels.com/photos/1497582/pexels-photo-1497582.jpeg?cs=srgb&dl=pexels-spencer-gurley-films-1497582.jpg&fm=jpg&w=1280&h=854\"\n",
    "SEA_CAVE_IMAGE = \"https://images.pexels.com/photos/163872/italy-cala-gonone-air-sky-163872.jpeg?cs=srgb&dl=pexels-pixabay-163872.jpg&fm=jpg&w=1280&h=960\"\n",
    "\n",
    "images_objects = [Image.open(requests.get(url, stream=True).raw) for url in IMAGE_URLS]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eebb21a8",
   "metadata": {},
   "source": [
    "## Helper functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d98bb10",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "from typing import Iterable\n",
    "\n",
    "import ipyplot\n",
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity as _cosine_similarity\n",
    "\n",
    "\n",
    "def display_images(indices: \"Iterable[int] | None\" = None, **kwargs):\n",
    "    indices = indices if indices is not None else range(len(IMAGE_URLS))\n",
    "    ipyplot.plot_images([IMAGE_URLS[i] for i in indices], **kwargs)\n",
    "\n",
    "\n",
    "def draw_bounding_box(image: Image.Image, bounding_box: npt.NDArray[np.float_]) -> Image.Image:\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    draw.rectangle(bounding_box.tolist(), outline =\"red\", width=10)\n",
    "    return image\n",
    "\n",
    "\n",
    "def display_crops(image_indices: Iterable[int], bounding_boxes: npt.NDArray[np.float_], **kwargs):\n",
    "    cropped_images = [draw_bounding_box(images_objects[image_index].copy(), bb) for image_index, bb in zip(image_indices, bounding_boxes)]\n",
    "    ipyplot.plot_images(cropped_images, **kwargs)\n",
    "\n",
    "\n",
    "def cosine_similarity(query: npt.NDArray[np.float_], features: npt.NDArray[np.float_]) -> npt.NDArray[np.float_]:\n",
    "    if len(query.shape) == 1:\n",
    "        query = query[np.newaxis]\n",
    "    return _cosine_similarity(query, features)[0]\n",
    "\n",
    "\n",
    "def arg_rank_by_cosine_similarity(query: npt.NDArray[np.float_], features: npt.NDArray[np.float_], take: \"int | None\" = None) -> npt.NDArray[np.int_]:\n",
    "    result = np.argsort(cosine_similarity(query, features))[::-1]\n",
    "    if take is not None:\n",
    "        return result[:take]\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53877e8",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "display_images()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816dbe2c",
   "metadata": {},
   "source": [
    "## Basic interface to run models\n",
    "\n",
    "Generic code to run a model inference on PyTorch.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6e8961",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from mozuma.torch.callbacks import TorchRunnerCallbackType\n",
    "from mozuma.torch.datasets import ListDatasetIndexed, TorchDataset\n",
    "from mozuma.torch.modules import TorchModel\n",
    "from mozuma.torch.runners import TorchInferenceRunner\n",
    "from mozuma.torch.options import TorchRunnerOptions\n",
    "\n",
    "\n",
    "def run_torch_model_inference(\n",
    "    model: TorchModel,\n",
    "    callbacks: \"list[TorchRunnerCallbackType]\",\n",
    "    dataset: \"TorchDataset | None\" = None,\n",
    ") -> None:\n",
    "    \"\"\"Runs inference for a PyTorch model\"\"\"\n",
    "    # Setting the dataset to images if not defined\n",
    "    dataset = dataset or ListDatasetIndexed(indices=IMAGE_URLS, objects=images_objects)\n",
    "\n",
    "    runner = TorchInferenceRunner(\n",
    "        model=model,\n",
    "        dataset=dataset,\n",
    "        callbacks=callbacks,\n",
    "        options=TorchRunnerOptions(\n",
    "            device=torch.device(\"cpu\"), data_loader_options={\"batch_size\": 20}\n",
    "        ),\n",
    "    )\n",
    "    runner.run()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85d29a1",
   "metadata": {},
   "source": [
    "## Generic function to compute features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088a5449",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "from mozuma.callbacks import CollectFeaturesInMemory\n",
    "\n",
    "\n",
    "def collect_features(\n",
    "    model: TorchModel, dataset: \"TorchDataset | None\" = None\n",
    ") -> npt.NDArray[np.float_]:\n",
    "    features = CollectFeaturesInMemory()\n",
    "    run_torch_model_inference(model=model, callbacks=[features], dataset=dataset)\n",
    "    if dataset is None:\n",
    "        assert features.indices == IMAGE_URLS, features.indices\n",
    "    return features.features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56bd07ba",
   "metadata": {},
   "source": [
    "## Find an image from a text query\n",
    "\n",
    "<p style=\"text-align: center;\">A dog at the beach</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38047c0",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: add noise with dog images\n",
    "from mozuma.models.clip.pretrained import (\n",
    "    torch_clip_image_encoder,\n",
    "    torch_clip_text_encoder,\n",
    ")\n",
    "from mozuma.torch.datasets import ListDataset\n",
    "\n",
    "\n",
    "clip_image_features = collect_features(model=torch_clip_image_encoder(\"ViT-B/32\"))\n",
    "clip_text_features = collect_features(\n",
    "    model=torch_clip_text_encoder(\"ViT-B/32\"),\n",
    "    dataset=ListDataset([\"a dog at the beach\"]),\n",
    ")\n",
    "display_images(\n",
    "    arg_rank_by_cosine_similarity(clip_text_features, clip_image_features, take=1), img_width=500\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cea8c02",
   "metadata": {},
   "source": [
    "# Generic function to compute bounding boxes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38ab60b",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "from mozuma.callbacks import CollectBoundingBoxesInMemory\n",
    "\n",
    "\n",
    "def collect_bbox(\n",
    "    model: TorchModel,\n",
    ") -> \"tuple[npt.NDArray[np.str_], npt.NDArray[np.float_], npt.NDArray[np.float_]]\":\n",
    "    bbox = CollectBoundingBoxesInMemory()\n",
    "    run_torch_model_inference(model=model, callbacks=[bbox])\n",
    "    assert bbox.indices == IMAGE_URLS, bbox.indices\n",
    "    # Flattening the bounding boxes\n",
    "    indices: \"list[str]\" = []\n",
    "    features: \"list[npt.NDArray[np.float_]]\" = []\n",
    "    boxes: \"list[npt.NDArray[np.float_]]\" = []\n",
    "    for index, box_list in zip(bbox.indices, bbox.bounding_boxes):\n",
    "        indices += [index] * len(box_list.bounding_boxes)\n",
    "        boxes.append(box_list.bounding_boxes)\n",
    "        if box_list.features is None:\n",
    "            raise ValueError(\"This model does not returned features\")\n",
    "        features.append(box_list.features)\n",
    "    return np.array(indices, dtype=str), np.vstack(boxes), np.vstack(features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3d7a23",
   "metadata": {},
   "source": [
    "## Find images with similar objects\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84f3908",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "from mozuma.models.vinvl.pretrained import torch_vinvl_detector\n",
    "\n",
    "bbox_indices, bbox_boxes, bbox_features = collect_bbox(model=torch_vinvl_detector())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595477d1",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "# Find an image of a paddle\n",
    "paddle_coordinates = np.array([ 899.95416,  581.6102 , 1105.5442 ,  640.5274 ])\n",
    "paddle_box_index = np.argmin(cdist(paddle_coordinates[np.newaxis], bbox_boxes[bbox_indices == KAYAK_IMAGE]))\n",
    "paddle_bounding_box = bbox_boxes[bbox_indices == KAYAK_IMAGE][paddle_box_index]\n",
    "paddle_features = bbox_features[bbox_indices == KAYAK_IMAGE][paddle_box_index]\n",
    "\n",
    "display_crops([IMAGE_URLS.index(KAYAK_IMAGE)], paddle_bounding_box[np.newaxis], img_width=500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dcff5ae",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Finding similar objects\n",
    "top_matching_objects = arg_rank_by_cosine_similarity(paddle_features, bbox_features, take=12)[1:]\n",
    "top_matching_objects_image_urls = bbox_indices[top_matching_objects]\n",
    "\n",
    "display_crops([IMAGE_URLS.index(img_url) for img_url in top_matching_objects_image_urls], bbox_boxes[top_matching_objects, :], img_width=500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db30e6b4",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "np.sort(cosine_similarity(paddle_features, bbox_features))[-12:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f36febc",
   "metadata": {},
   "source": [
    "# places + kayak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5bcdf2",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "from mozuma.models.densenet.pretrained import torch_densenet_places365\n",
    "\n",
    "densenet_places_features = collect_features(model=torch_densenet_places365())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2b81d4",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "display_images([IMAGE_URLS.index(SEA_CAVE_IMAGE)], img_width=500)\n",
    "# TODO add more cave images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1da88b",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Find images with an object that looks like a paddle with threshold 0.5 on cosine similarity\n",
    "paddle_objects = cosine_similarity(paddle_features, bbox_features) > 0.5\n",
    "image_urls_with_paddles = set(bbox_indices[paddle_objects])\n",
    "\n",
    "# Ranking image with paddles with the places365 similarity\n",
    "display_images([\n",
    "    img_idx\n",
    "    for img_idx in arg_rank_by_cosine_similarity(\n",
    "        densenet_places_features[IMAGE_URLS.index(SEA_CAVE_IMAGE)],\n",
    "        densenet_places_features,\n",
    "    )\n",
    "    if IMAGE_URLS[img_idx] in image_urls_with_paddles\n",
    "][:1], img_width=500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06f59eb",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md"
  },
  "kernelspec": {
   "display_name": "Python 3.7.12 (conda)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
