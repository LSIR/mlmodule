{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train CIFAR10 Image Classification on top of ResNet18 features from ImageNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import `mlmodule` modules for the task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lebret/lib/mlmodule/venv/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from mlmodule.models.resnet.modules import TorchResNetModule\n",
    "from mlmodule.models.classification import LinearClassifierTorchModule\n",
    "from mlmodule.torch.datasets import TorchTrainingDataset\n",
    "from mlmodule.torch.runners import TorchTrainingRunner\n",
    "from mlmodule.torch.runners import TorchInferenceRunner\n",
    "from mlmodule.torch.options import TorchTrainingOptions\n",
    "from mlmodule.torch.options import TorchRunnerOptions\n",
    "from mlmodule.labels.base import LabelSet\n",
    "from mlmodule.callbacks.memory import (\n",
    "    CollectFeaturesInMemory,\n",
    ")\n",
    "from mlmodule.torch.datasets import (\n",
    "    ListDataset,\n",
    "    ListDatasetIndexed,\n",
    ")\n",
    "from mlmodule.states import StateKey\n",
    "from mlmodule.stores import Store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enable logging into notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s | %(levelname)s : %(message)s',\n",
    "                     level=logging.INFO, stream=sys.stdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Load CIFAR10 dataset from torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from torchvision.datasets import CIFAR10\n",
    "\n",
    "root_dir = '/home/lebret/data'\n",
    "train_cifar10 = CIFAR10(root=root_dir, train=True, download=True,  transform=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Format inputs and labels for `mlmodule`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_dict = {0:\"airplane\", 1:\"automobile\", 2:\"bird\", 3:\"cat\", 4:\"deer\", 5:\"dog\", 6:\"frog\", 7:\"horse\", 8:\"ship\", 9:\"truck\"}\n",
    "train_samples = [(img, labels_dict[label]) for img, label in train_cifar10]\n",
    "train_images, train_labels = zip(*train_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Load `resnet18` pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-11 14:09:34,865 | INFO : Found credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    }
   ],
   "source": [
    "torch_device = \"cuda\"\n",
    "resnet = TorchResNetModule(\n",
    "    resnet_arch=\"resnet18\", \n",
    "    device=torch_device,\n",
    "    training_mode=\"features\"\n",
    ")\n",
    "Store().load(resnet, StateKey(resnet.state_type, training_id=\"imagenet\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Extract image features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [02:42<00:00,  9.62it/s]\n"
     ]
    }
   ],
   "source": [
    "# Callbacks\n",
    "ff = CollectFeaturesInMemory()\n",
    "\n",
    "# Runner\n",
    "runner = TorchInferenceRunner(\n",
    "    model=resnet,\n",
    "    dataset=ListDataset(train_images),\n",
    "    callbacks=[ff],\n",
    "    options=TorchRunnerOptions(\n",
    "        data_loader_options={'batch_size': 32},\n",
    "        device=torch_device, \n",
    "        tqdm_enabled=True\n",
    "    ),\n",
    ")\n",
    "runner.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Create a linear classifier on top of ResNet features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlmodule.models.classification import LinearClassifierTorchModule\n",
    "\n",
    "labels = list(labels_dict.values())\n",
    "labels.sort()\n",
    "label_set = LabelSet(\n",
    "            label_set_unique_id=\"cifar10\",\n",
    "            label_list=labels\n",
    "        )\n",
    "        \n",
    "classifier = LinearClassifierTorchModule(\n",
    "    in_features=ff.features.shape[1],\n",
    "    label_set=label_set\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Create train and validation splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# split samples into train and valid sets\n",
    "train_indices, valid_indices = torch.split(torch.randperm(len(ff.indices)), int(len(ff.indices)*.9))\n",
    "# define training set\n",
    "train_dset = TorchTrainingDataset(\n",
    "    dataset=ListDatasetIndexed(train_indices, ff.features[train_indices]),\n",
    "    targets=label_set.get_label_ids([train_labels[idx] for idx in train_indices])\n",
    ")\n",
    "# define valid set\n",
    "valid_dset = TorchTrainingDataset(\n",
    "    dataset=ListDatasetIndexed(valid_indices, ff.features[valid_indices]),\n",
    "    targets=label_set.get_label_ids([train_labels[idx] for idx in valid_indices])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Train the image classifier using `TorchTrainingRunner` module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-11 14:46:01,176 | INFO : Engine run starting with max_epochs=5.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/5]: 100%|██████████| 1407/1407 [00:14<00:00, 96.65it/s, avg_loss=0.448] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-11 14:46:22,973 | INFO : Engine run starting with max_epochs=1.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-11 14:46:33,581 | INFO : Epoch[1] Complete. Time taken: 00:00:11\n",
      "2022-05-11 14:46:33,582 | INFO : Engine run complete. Time taken: 00:00:11\n",
      "2022-05-11 14:46:33,583 | INFO : Epoch 1 - Evaluation time (seconds): 10.61 - Train metrics\n",
      "\n",
      "2022-05-11 14:46:33,584 | INFO : \tf1: 0.8512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-11 14:46:33,585 | INFO : \tacc: 0.8524\n",
      "2022-05-11 14:46:33,586 | INFO : \tce_loss: 0.4333\n",
      "2022-05-11 14:46:33,586 | INFO : Engine run starting with max_epochs=1.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-11 14:46:34,780 | INFO : Epoch[1] Complete. Time taken: 00:00:01\n",
      "2022-05-11 14:46:34,781 | INFO : Engine run complete. Time taken: 00:00:01\n",
      "2022-05-11 14:46:34,781 | INFO : Epoch 1 - Evaluation time (seconds): 1.19 - Test metrics\n",
      "\n",
      "2022-05-11 14:46:34,782 | INFO : \tf1: 0.8437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-11 14:46:34,782 | INFO : \tacc: 0.8440\n",
      "2022-05-11 14:46:34,783 | INFO : \tce_loss: 0.4312\n",
      "2022-05-11 14:46:34,784 | INFO : Epoch[1] Complete. Time taken: 00:00:34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [2/5]: 100%|██████████| 1407/1407 [00:14<00:00, 96.02it/s, avg_loss=0.406] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-11 14:46:49,437 | INFO : Engine run starting with max_epochs=1.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-11 14:46:59,957 | INFO : Epoch[1] Complete. Time taken: 00:00:11\n",
      "2022-05-11 14:46:59,958 | INFO : Engine run complete. Time taken: 00:00:11\n",
      "2022-05-11 14:46:59,958 | INFO : Epoch 2 - Evaluation time (seconds): 10.52 - Train metrics\n",
      "\n",
      "2022-05-11 14:46:59,959 | INFO : \tf1: 0.8618\n",
      "2022-05-11 14:46:59,960 | INFO : \tacc: 0.8628\n",
      "2022-05-11 14:46:59,960 | INFO : \tce_loss: 0.4002\n",
      "2022-05-11 14:46:59,961 | INFO : Engine run starting with max_epochs=1.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-11 14:47:01,118 | INFO : Epoch[1] Complete. Time taken: 00:00:01\n",
      "2022-05-11 14:47:01,119 | INFO : Engine run complete. Time taken: 00:00:01\n",
      "2022-05-11 14:47:01,120 | INFO : Epoch 2 - Evaluation time (seconds): 1.16 - Test metrics\n",
      "\n",
      "2022-05-11 14:47:01,121 | INFO : \tf1: 0.8491\n",
      "2022-05-11 14:47:01,122 | INFO : \tacc: 0.8492\n",
      "2022-05-11 14:47:01,122 | INFO : \tce_loss: 0.4078\n",
      "2022-05-11 14:47:01,123 | INFO : Epoch[2] Complete. Time taken: 00:00:26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [3/5]: 100%|██████████| 1407/1407 [00:14<00:00, 96.53it/s, avg_loss=0.387] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-11 14:47:15,701 | INFO : Engine run starting with max_epochs=1.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-11 14:47:26,240 | INFO : Epoch[1] Complete. Time taken: 00:00:11\n",
      "2022-05-11 14:47:26,241 | INFO : Engine run complete. Time taken: 00:00:11\n",
      "2022-05-11 14:47:26,242 | INFO : Epoch 3 - Evaluation time (seconds): 10.54 - Train metrics\n",
      "\n",
      "2022-05-11 14:47:26,242 | INFO : \tf1: 0.8664\n",
      "2022-05-11 14:47:26,243 | INFO : \tacc: 0.8673\n",
      "2022-05-11 14:47:26,244 | INFO : \tce_loss: 0.3854\n",
      "2022-05-11 14:47:26,244 | INFO : Engine run starting with max_epochs=1.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-11 14:47:27,438 | INFO : Epoch[1] Complete. Time taken: 00:00:01\n",
      "2022-05-11 14:47:27,439 | INFO : Engine run complete. Time taken: 00:00:01\n",
      "2022-05-11 14:47:27,439 | INFO : Epoch 3 - Evaluation time (seconds): 1.19 - Test metrics\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-11 14:47:27,440 | INFO : \tf1: 0.8532\n",
      "2022-05-11 14:47:27,440 | INFO : \tacc: 0.8532\n",
      "2022-05-11 14:47:27,441 | INFO : \tce_loss: 0.4006\n",
      "2022-05-11 14:47:27,441 | INFO : Epoch[3] Complete. Time taken: 00:00:26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [4/5]: 100%|██████████| 1407/1407 [00:14<00:00, 96.07it/s, avg_loss=0.375] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-11 14:47:42,090 | INFO : Engine run starting with max_epochs=1.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-11 14:47:52,878 | INFO : Epoch[1] Complete. Time taken: 00:00:11\n",
      "2022-05-11 14:47:52,878 | INFO : Engine run complete. Time taken: 00:00:11\n",
      "2022-05-11 14:47:52,879 | INFO : Epoch 4 - Evaluation time (seconds): 10.79 - Train metrics\n",
      "\n",
      "2022-05-11 14:47:52,880 | INFO : \tf1: 0.8688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-11 14:47:52,880 | INFO : \tacc: 0.8696\n",
      "2022-05-11 14:47:52,881 | INFO : \tce_loss: 0.3762\n",
      "2022-05-11 14:47:52,882 | INFO : Engine run starting with max_epochs=1.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-11 14:47:54,015 | INFO : Epoch[1] Complete. Time taken: 00:00:01\n",
      "2022-05-11 14:47:54,015 | INFO : Engine run complete. Time taken: 00:00:01\n",
      "2022-05-11 14:47:54,016 | INFO : Epoch 4 - Evaluation time (seconds): 1.13 - Test metrics\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-11 14:47:54,017 | INFO : \tf1: 0.8543\n",
      "2022-05-11 14:47:54,017 | INFO : \tacc: 0.8542\n",
      "2022-05-11 14:47:54,018 | INFO : \tce_loss: 0.3976\n",
      "2022-05-11 14:47:54,018 | INFO : Epoch[4] Complete. Time taken: 00:00:27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [5/5]: 100%|██████████| 1407/1407 [00:14<00:00, 96.17it/s, avg_loss=0.367] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-11 14:48:08,649 | INFO : Engine run starting with max_epochs=1.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-11 14:48:19,469 | INFO : Epoch[1] Complete. Time taken: 00:00:11\n",
      "2022-05-11 14:48:19,470 | INFO : Engine run complete. Time taken: 00:00:11\n",
      "2022-05-11 14:48:19,470 | INFO : Epoch 5 - Evaluation time (seconds): 10.82 - Train metrics\n",
      "\n",
      "2022-05-11 14:48:19,471 | INFO : \tf1: 0.8703\n",
      "2022-05-11 14:48:19,472 | INFO : \tacc: 0.8712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-11 14:48:19,472 | INFO : \tce_loss: 0.3698\n",
      "2022-05-11 14:48:19,473 | INFO : Engine run starting with max_epochs=1.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-11 14:48:20,656 | INFO : Epoch[1] Complete. Time taken: 00:00:01\n",
      "2022-05-11 14:48:20,657 | INFO : Engine run complete. Time taken: 00:00:01\n",
      "2022-05-11 14:48:20,658 | INFO : Epoch 5 - Evaluation time (seconds): 1.18 - Test metrics\n",
      "\n",
      "2022-05-11 14:48:20,658 | INFO : \tf1: 0.8542\n",
      "2022-05-11 14:48:20,659 | INFO : \tacc: 0.8542\n",
      "2022-05-11 14:48:20,660 | INFO : \tce_loss: 0.3963\n",
      "2022-05-11 14:48:20,660 | INFO : Epoch[5] Complete. Time taken: 00:00:27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-11 14:48:20,664 | INFO : Engine run starting with max_epochs=1.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-11 14:48:31,485 | INFO : Epoch[1] Complete. Time taken: 00:00:11\n",
      "2022-05-11 14:48:31,486 | INFO : Engine run complete. Time taken: 00:00:11\n",
      "2022-05-11 14:48:31,487 | INFO : Epoch 5 - Evaluation time (seconds): 10.82 - Train metrics\n",
      "\n",
      "2022-05-11 14:48:31,487 | INFO : \tf1: 0.8703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-11 14:48:31,488 | INFO : \tacc: 0.8712\n",
      "2022-05-11 14:48:31,489 | INFO : \tce_loss: 0.3698\n",
      "2022-05-11 14:48:31,489 | INFO : Engine run starting with max_epochs=1.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-11 14:48:32,681 | INFO : Epoch[1] Complete. Time taken: 00:00:01\n",
      "2022-05-11 14:48:32,681 | INFO : Engine run complete. Time taken: 00:00:01\n",
      "2022-05-11 14:48:32,682 | INFO : Epoch 5 - Evaluation time (seconds): 1.19 - Test metrics\n",
      "\n",
      "2022-05-11 14:48:32,682 | INFO : \tf1: 0.8542\n",
      "2022-05-11 14:48:32,683 | INFO : \tacc: 0.8542\n",
      "2022-05-11 14:48:32,683 | INFO : \tce_loss: 0.3963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-11 14:48:32,684 | INFO : Engine run complete. Time taken: 00:02:32\n"
     ]
    }
   ],
   "source": [
    "from ignite.metrics import Precision, Recall, Loss, Accuracy\n",
    "from mlmodule.callbacks.states import SaveModelState\n",
    "from mlmodule.stores.local import LocalStateStore\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# define the evaluation metrics\n",
    "precision = Precision(average=False)\n",
    "recall = Recall(average=False)\n",
    "F1 = (precision * recall * 2 / (precision + recall)).mean()\n",
    "\n",
    "# Callbacks\n",
    "model_state = SaveModelState(\n",
    "    store=LocalStateStore('/home/lebret/data/mlmodule'), \n",
    "    state_key=StateKey(classifier.state_type, 'train-1'))\n",
    "# define a loss function\n",
    "loss_fn =  F.cross_entropy\n",
    "\n",
    "# define the trainer\n",
    "trainer = TorchTrainingRunner(\n",
    "    model=classifier,\n",
    "    dataset=(train_dset, valid_dset),\n",
    "    callbacks=[model_state],\n",
    "    options=TorchTrainingOptions(\n",
    "        data_loader_options={'batch_size': 32},\n",
    "        criterion=loss_fn,\n",
    "        optimizer=optim.Adam(classifier.parameters(), lr=1e-3),\n",
    "        metrics={\n",
    "            \"pre\": precision,\n",
    "            \"recall\": recall,\n",
    "            \"f1\": F1,\n",
    "            \"acc\": Accuracy(),\n",
    "            \"ce_loss\": Loss(loss_fn),\n",
    "        },\n",
    "        validate_every=1,\n",
    "        checkpoint_every=3,\n",
    "        num_epoch=5,\n",
    "        tqdm_enabled=True,\n",
    "    ),\n",
    ")\n",
    "trainer.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Do evaluation on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:22<00:00, 14.14it/s]\n",
      "100%|██████████| 313/313 [00:00<00:00, 2084.19it/s]\n"
     ]
    }
   ],
   "source": [
    "from mlmodule.callbacks.memory import CollectLabelsInMemory\n",
    "\n",
    "test_cifar10 = CIFAR10(root=root_dir, train=False, download=True,  transform=None)\n",
    "test_samples = [(img, labels_dict[label]) for img, label in test_cifar10]\n",
    "test_images, test_labels = zip(*test_samples)\n",
    "\n",
    "# Callbacks\n",
    "ff_test = CollectFeaturesInMemory()\n",
    "score_test = CollectLabelsInMemory()\n",
    "\n",
    "# Extract the image features\n",
    "features_test_runner = TorchInferenceRunner(\n",
    "    model=resnet,\n",
    "    dataset=ListDataset(test_images),\n",
    "    callbacks=[ff_test],\n",
    "    options=TorchRunnerOptions(\n",
    "        data_loader_options={'batch_size': 32},\n",
    "        device=torch_device, \n",
    "        tqdm_enabled=True\n",
    "    ),\n",
    ")\n",
    "features_test_runner.run()\n",
    "\n",
    "# Do the predictions\n",
    "scores_test_runner = TorchInferenceRunner(\n",
    "    model=classifier,\n",
    "    dataset=ListDataset(ff_test.features),\n",
    "    callbacks=[score_test],\n",
    "    options=TorchRunnerOptions(\n",
    "        data_loader_options={'batch_size': 32},\n",
    "        device=torch_device, \n",
    "        tqdm_enabled=True\n",
    "    ),\n",
    ")\n",
    "scores_test_runner.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Print classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    airplane       0.88      0.85      0.86      1000\n",
      "  automobile       0.93      0.92      0.93      1000\n",
      "        bird       0.88      0.73      0.79      1000\n",
      "         cat       0.81      0.66      0.73      1000\n",
      "        deer       0.79      0.85      0.82      1000\n",
      "         dog       0.74      0.86      0.80      1000\n",
      "        frog       0.78      0.96      0.86      1000\n",
      "       horse       0.93      0.79      0.85      1000\n",
      "        ship       0.87      0.96      0.91      1000\n",
      "       truck       0.94      0.91      0.93      1000\n",
      "\n",
      "    accuracy                           0.85     10000\n",
      "   macro avg       0.85      0.85      0.85     10000\n",
      "weighted avg       0.85      0.85      0.85     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(test_labels, score_test.labels))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "87ff38510d400b07e30cf74ae9dd54446c13e53a2020eb935b0a431823d158d6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 (conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
