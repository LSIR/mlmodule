{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.11 64-bit (conda)"
  },
  "interpreter": {
   "hash": "355aa20d4ad8dc39dec281b3934cd3d34f60aab58844993f6361175a2b6f9a83"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from mlmodule.utils import list_files_in_dir\n",
    "from mlmodule.torch.data.images import ImageDataset\n",
    "from mlmodule.contrib.arcface import ArcFaceFeatures\n",
    "from mlmodule.contrib.magface import MagFaceFeatures\n",
    "from mlmodule.contrib.mtcnn import MTCNNDetector\n",
    "from mlmodule.torch.data.box import BoundingBoxDataset\n",
    "from mlmodule.box import BBoxOutput\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import numpy as np\n",
    "from typing import List\n",
    "from facenet_pytorch.models.utils.detect_face import crop_resize\n",
    "from PIL import Image\n",
    "import seaborn as sns\n",
    "sns.set(style=\"white\")\n",
    "%matplotlib inline\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "%env AWS_ACCESS_KEY_ID = <please your key id here>\n",
    "%env AWS_SECRET_ACCESS_KEY = <please your secret access key here>"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# load models\n",
    "device = torch.device('cuda:0')\n",
    "arcface = ArcFaceFeatures(device=device).load()\n",
    "magface = MagFaceFeatures(device=device).load()\n",
    "mtcnn = MTCNNDetector(device=device, image_size=(720, 720), min_face_size=20).load()\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# run face detection first\n",
    "base_path = \"../tests/fixtures/berset\"\n",
    "file_names = list_files_in_dir(base_path, allowed_extensions=('jpg',))\n",
    "dataset = ImageDataset(file_names)\n",
    "# Detect faces first\n",
    "file_names, outputs = mtcnn.bulk_inference(dataset)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Flattening all detected faces\n",
    "bboxes: List[BBoxOutput]\n",
    "indices: List[str]\n",
    "indices, file_names, bboxes = zip(*[\n",
    "    (f'{fn}_{i}', fn, bbox) for fn, bbox_list in zip(file_names, outputs) for i, bbox in enumerate(bbox_list)\n",
    "])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Get face features with ArcFace\n",
    "# 1. Create a dataset for the bounding boxes\n",
    "bbox_features = BoundingBoxDataset(indices, file_names, bboxes)\n",
    "# 2. Get features from ArcFace\n",
    "d_indices, arcface_features = arcface.bulk_inference(\n",
    "    bbox_features,\n",
    "    remove_bad_quality_faces=False,\n",
    "    data_loader_options={'batch_size': 12,\n",
    "                         'num_workers': 0, 'pin_memory': True},\n",
    "    tqdm_enabled=True)\n",
    "\n",
    "# Get face features with MagFace\n",
    "# 1. Create a dataset for the bounding boxes\n",
    "bbox_features = BoundingBoxDataset(indices, file_names, bboxes)\n",
    "# 2. Get features from MagFace\n",
    "d_indices, magface_features = magface.bulk_inference(\n",
    "    bbox_features,\n",
    "    remove_bad_quality_faces=False,\n",
    "    data_loader_options={'batch_size': 12,\n",
    "                         'num_workers': 0, 'pin_memory': True},\n",
    "    tqdm_enabled=True)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def image_grid(array, ncols=10):\n",
    "    index, height, width, channels = array.shape\n",
    "    nrows = index//ncols\n",
    "\n",
    "    img_grid = (array.reshape(nrows, ncols, height, width, channels)\n",
    "                .swapaxes(1, 2)\n",
    "                .reshape(height*nrows, width*ncols, channels))\n",
    "\n",
    "    return img_grid\n",
    "\n",
    "\n",
    "img_arr = []\n",
    "img_size = []\n",
    "aspect_ratios = []\n",
    "for ele, file_name in enumerate(file_names):\n",
    "    img = Image.open(file_name)\n",
    "    img_size.append(img.size)\n",
    "    width, height = img.size\n",
    "    aspect_ratios.append([x/target for x, target in zip((height, width), (720, 720))])\n",
    "    box = np.array([bboxes[ele].bounding_box[0].x,\n",
    "                   bboxes[ele].bounding_box[0].y, bboxes[ele].bounding_box[1].x,\n",
    "                   bboxes[ele].bounding_box[1].y])\n",
    "    cropped_face = np.asarray(crop_resize(img, box, image_size=112))\n",
    "    img_arr.append(cropped_face)\n",
    "\n",
    "result = image_grid(np.array(img_arr), ncols=len(file_names))\n",
    "fig = plt.figure(figsize=(20., 20.))\n",
    "plt.imshow(result)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Face similarity with ArcFace"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "sim_mat = arcface_features @ arcface_features.T\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "ax = sns.heatmap(sim_mat, cmap=\"PuRd\", annot=True)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Face Similarity with MagFace"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "normalized_features = magface_features / np.linalg.norm(magface_features, axis=1, keepdims=True)\n",
    "sim_mat = normalized_features @ normalized_features.T\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "ax = sns.heatmap(sim_mat, cmap=\"PuRd\", annot=True)\n"
   ],
   "outputs": [],
   "metadata": {}
  }
 ]
}